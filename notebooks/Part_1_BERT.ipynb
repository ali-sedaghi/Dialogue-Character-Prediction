{"cells":[{"cell_type":"markdown","metadata":{"id":"QrJqR7Wed3ld"},"source":["# Installing Requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-09T14:54:18.614117Z","iopub.status.busy":"2022-07-09T14:54:18.613356Z","iopub.status.idle":"2022-07-09T14:54:33.089518Z","shell.execute_reply":"2022-07-09T14:54:33.087806Z","shell.execute_reply.started":"2022-07-09T14:54:18.614087Z"},"id":"reY2YZVQ5Wqc","outputId":"3c97a7e4-4970-4feb-e540-fa01d2373a39","trusted":true},"outputs":[],"source":["# !pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"2dGZAg9Vd6jN"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:16:05.272393Z","iopub.status.busy":"2022-07-10T08:16:05.271708Z","iopub.status.idle":"2022-07-10T08:16:13.783511Z","shell.execute_reply":"2022-07-10T08:16:13.782478Z","shell.execute_reply.started":"2022-07-10T08:16:05.272304Z"},"id":"6QmAPOj_5gOk","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import Trainer, TrainingArguments, BertTokenizer, BertForMaskedLM\n"]},{"cell_type":"markdown","metadata":{"id":"suKSQsjZegfG"},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:16:16.761770Z","iopub.status.busy":"2022-07-10T08:16:16.760960Z","iopub.status.idle":"2022-07-10T08:16:16.767280Z","shell.execute_reply":"2022-07-10T08:16:16.765914Z","shell.execute_reply.started":"2022-07-10T08:16:16.761733Z"},"id":"UuEIZzCG6_L6","trusted":true},"outputs":[],"source":["MAX_LEN = 64\n","TRAIN_BATCH_SIZE = 64\n","VALID_BATCH_SIZE = 32\n","LEARNING_RATE = 1e-05\n","NUM_CLASSES = 6"]},{"cell_type":"markdown","metadata":{"id":"KJoMHVpJeKPT"},"source":["# Processing data"]},{"cell_type":"markdown","metadata":{"id":"m3sDa07veMGJ"},"source":["## Creating a dataframe"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:16:19.767175Z","iopub.status.busy":"2022-07-10T08:16:19.766587Z","iopub.status.idle":"2022-07-10T08:16:19.809343Z","shell.execute_reply":"2022-07-10T08:16:19.808423Z","shell.execute_reply.started":"2022-07-10T08:16:19.767137Z"},"id":"_PHxrSzw5aW_","trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/friends-dialogues/dialogues_cleaned.csv\")\n","df = df.drop(df[df[\"person\"]==\"person\"].index)"]},{"cell_type":"markdown","metadata":{"id":"y-RDeJ3eeOPi"},"source":["## Label Encoder"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:16:48.083742Z","iopub.status.busy":"2022-07-10T08:16:48.083377Z","iopub.status.idle":"2022-07-10T08:16:48.096534Z","shell.execute_reply":"2022-07-10T08:16:48.095598Z","shell.execute_reply.started":"2022-07-10T08:16:48.083712Z"},"id":"CREreZ8JGSSl","trusted":true},"outputs":[],"source":["rachel_dlgs = df[df[\"person\"]==\"rachel\"][\"dialogue\"].values\n","monica_dlgs = df[df[\"person\"]==\"monica\"][\"dialogue\"].values\n","ross_dlgs = df[df[\"person\"]==\"ross\"][\"dialogue\"].values"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:16:50.637859Z","iopub.status.busy":"2022-07-10T08:16:50.637505Z","iopub.status.idle":"2022-07-10T08:17:08.455065Z","shell.execute_reply":"2022-07-10T08:17:08.453957Z","shell.execute_reply.started":"2022-07-10T08:16:50.637827Z"},"id":"sQacqckEDrzH","outputId":"629e8a9f-611f-4fa3-a888-e8e60a4ea97d","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa57aad85a22431bbf4a1b9a6e3fba4a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21b9f89cc94a4aae9046ca8354f67f8d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a16ac0cb2a640bbb43847621c9e325b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69b2cae656c848edb9a6bf0403fcc957","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', mask_toke=\"[MASK]\", sep_token=\"[SEP]\", pad_token=\"[PAD]\")\n","\n","def tokenize_batch(batch):\n","    return [tokenizer.convert_tokens_to_ids(sent) for sent in batch]\n","\n","def untokenize_batch(batch):\n","    return [tokenizer.convert_ids_to_tokens(sent) for sent in batch]\n","\n","def detokenize(sent):\n","    \"\"\" Roughly detokenizes (mainly undoes wordpiece) \"\"\"\n","    new_sent = []\n","    for i, tok in enumerate(sent):\n","        if tok.startswith(\"##\"):\n","            new_sent[len(new_sent) - 1] = new_sent[len(new_sent) - 1] + tok[2:]\n","        else:\n","            new_sent.append(tok)\n","    return new_sent\n","\n","CLS = '[CLS]'\n","SEP = '[SEP]'\n","MASK = '[MASK]'\n","mask_id = tokenizer.convert_tokens_to_ids([MASK])[0]\n","sep_id = tokenizer.convert_tokens_to_ids([SEP])[0]\n","cls_id = tokenizer.convert_tokens_to_ids([CLS])[0]"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:17:08.457548Z","iopub.status.busy":"2022-07-10T08:17:08.456997Z","iopub.status.idle":"2022-07-10T08:17:08.469555Z","shell.execute_reply":"2022-07-10T08:17:08.468642Z","shell.execute_reply.started":"2022-07-10T08:17:08.457514Z"},"id":"l7WBVNEmE2jZ","trusted":true},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:17:08.473112Z","iopub.status.busy":"2022-07-10T08:17:08.471822Z","iopub.status.idle":"2022-07-10T08:17:08.483633Z","shell.execute_reply":"2022-07-10T08:17:08.482619Z","shell.execute_reply.started":"2022-07-10T08:17:08.473073Z"},"trusted":true},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):    \n","    def __init__(self, x):          \n","        self.x = x\n","     \n","    def __getitem__(self, idx):\n","        return tokenizer(self.x[idx])[\"input_ids\"]\n","        \n","    def __len__(self):\n","        return len(self.x)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:17:24.935446Z","iopub.status.busy":"2022-07-10T08:17:24.934917Z","iopub.status.idle":"2022-07-10T08:17:24.942883Z","shell.execute_reply":"2022-07-10T08:17:24.941391Z","shell.execute_reply.started":"2022-07-10T08:17:24.935397Z"},"trusted":true},"outputs":[],"source":["rachel_ds = Dataset(rachel_dlgs.tolist())\n","monica_ds = Dataset(monica_dlgs.tolist())\n","ross_ds = Dataset(ross_dlgs.tolist())\n"]},{"cell_type":"markdown","metadata":{"id":"nCOaV7fReVCS"},"source":["# Model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:17:29.652452Z","iopub.status.busy":"2022-07-10T08:17:29.651824Z","iopub.status.idle":"2022-07-10T08:17:29.660088Z","shell.execute_reply":"2022-07-10T08:17:29.657257Z","shell.execute_reply.started":"2022-07-10T08:17:29.652415Z"},"id":"nt_BjQds-wtR","trusted":true},"outputs":[],"source":["def compute_metrics(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=-1)\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    # recall = recall_score(y_true=labels, y_pred=pred)\n","    # precision = precision_score(y_true=labels, y_pred=pred)\n","    # f1 = f1_score(y_true=labels, y_pred=pred)\n","    return {\"accuracy\": accuracy} "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:17:50.051098Z","iopub.status.busy":"2022-07-10T08:17:50.050464Z","iopub.status.idle":"2022-07-10T08:17:50.123504Z","shell.execute_reply":"2022-07-10T08:17:50.122530Z","shell.execute_reply.started":"2022-07-10T08:17:50.051065Z"},"id":"XLQmN3cMy5iv","trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=10,              # total number of training epochs\n","    per_device_train_batch_size=TRAIN_BATCH_SIZE,  # batch size per device during training\n","    per_device_eval_batch_size=VALID_BATCH_SIZE,   # batch size for evaluation\n","    evaluation_strategy=\"epoch\",\n","    report_to=None\n",")\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:18:44.460847Z","iopub.status.busy":"2022-07-10T08:18:44.459803Z","iopub.status.idle":"2022-07-10T08:18:44.475922Z","shell.execute_reply":"2022-07-10T08:18:44.474826Z","shell.execute_reply.started":"2022-07-10T08:18:44.460809Z"},"id":"bu91ucL7T6dG","trusted":true},"outputs":[],"source":["rachel_trainer = Trainer(\n","    model=model,                 # the instantiated 🤗 Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=rachel_ds,         # training dataset\n","    eval_dataset=rachel_ds[:10],\n","#     compute_metrics=compute_metrics,\n","    data_collator=data_collator,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:18:47.343688Z","iopub.status.busy":"2022-07-10T08:18:47.343337Z","iopub.status.idle":"2022-07-10T08:18:47.362458Z","shell.execute_reply":"2022-07-10T08:18:47.361405Z","shell.execute_reply.started":"2022-07-10T08:18:47.343648Z"},"id":"n6bbhkgPJcmu","trusted":true},"outputs":[],"source":["import math\n","import time\n","\n","def generate_step(out, gen_idx, top_k=0, sample=False, return_list=True):\n","    \"\"\" Generate a word from from out[gen_idx]\n","    \n","    args:\n","        - out (torch.Tensor): tensor of logits of size batch_size x seq_len x vocab_size\n","        - gen_idx (int): location for which to generate for\n","        - top_k (int): if >0, only sample from the top k most probable words\n","        - sample (Bool): if True, sample from full distribution. Overridden by top_k \n","    \"\"\"\n","    # print(\"g\", out[\"logits\"].shape)\n","    logits = out[\"logits\"][:, gen_idx]\n","\n","    if top_k > 0:\n","        kth_vals, kth_idx = logits.topk(top_k, dim=-1)\n","        dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n","        idx = kth_idx.gather(dim=1, index=dist.sample().unsqueeze(-1)).squeeze(-1)\n","    elif sample:\n","        dist = torch.distributions.categorical.Categorical(logits=logits)\n","        idx = dist.sample().squeeze(-1)\n","    else:\n","        idx = torch.argmax(logits, dim=-1)\n","    return idx.tolist() if return_list else idx\n","  \n","  \n","def get_init_text(seed_text, max_len, batch_size = 1, rand_init=False):\n","    \"\"\" Get initial sentence by padding seed_text with either masks or random words to max_len \"\"\"\n","    batch = [seed_text + [MASK] * max_len + [SEP] for _ in range(batch_size)]\n","    return tokenize_batch(batch)\n","\n","def printer(sent, should_detokenize=True):\n","    if should_detokenize:\n","        sent = detokenize(sent)[1:-1]\n","    # print(\" \".join(sent))\n","\n","\n","def generate(n_samples, seed_text=\"[CLS]\", batch_size=10, max_len=15, leed_out_len=15,\n","             sample=True, top_k=100, temperature=1.0, burnin=200, max_iter=500, print_every=1):\n","    sentences = []\n","    n_batches = math.ceil(n_samples / batch_size)\n","    start_time = time.time()\n","    seed_len = len(seed_text)\n","    batch = get_init_text(seed_text, max_len, batch_size)\n","    \n","    for ii in range(max_len):\n","        inp = [sent[:seed_len+ii+leed_out_len]+[sep_id] for sent in batch]\n","        inp = torch.tensor(batch).cuda()\n","#         torch.tensor(batch)\n","        out = model(inp)\n","        # print(seed_len, ii, out.keys())\n","        idxs = generate_step(out, gen_idx=seed_len+ii, top_k=top_k, sample=sample)\n","        for jj in range(batch_size):\n","            batch[jj][seed_len+ii] = idxs[jj]\n","        \n","    return untokenize_batch(batch)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:19:22.078666Z","iopub.status.busy":"2022-07-10T08:19:22.078323Z","iopub.status.idle":"2022-07-10T08:20:43.582257Z","shell.execute_reply":"2022-07-10T08:20:43.580943Z","shell.execute_reply.started":"2022-07-10T08:19:22.078637Z"},"id":"n8HbLsxBDWQa","outputId":"d049b412-3886-45a9-fc5f-382bd8ac39d9","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1538\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 250\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.12.21 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.12.18"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20220710_081935-28yhr3xs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ysmn/huggingface/runs/28yhr3xs\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/ysmn/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 01:03, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>5.810031</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>6.001040</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>4.507802</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>3.436594</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>4.500379</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>4.900298</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>3.950582</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>3.790515</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>No log</td>\n","      <td>4.436484</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>No log</td>\n","      <td>4.807736</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 32\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]}],"source":["history = trainer.train()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:21:51.358630Z","iopub.status.busy":"2022-07-10T08:21:51.358283Z","iopub.status.idle":"2022-07-10T08:21:51.888155Z","shell.execute_reply":"2022-07-10T08:21:51.887198Z","shell.execute_reply.started":"2022-07-10T08:21:51.358600Z"},"id":"0WOP_SazJ4ME","trusted":true},"outputs":[],"source":["n_samples = 1\n","batch_size = 5\n","max_len = 40\n","top_k = 100\n","temperature = 1.0\n","leed_out_len = 5 # max_len\n","burnin = 250\n","sample = True\n","max_iter = 500\n","\n","# Choose the prefix context\n","seed_text = \"[CLS]\".split()\n","rachel_res = generate(n_samples, seed_text=seed_text, batch_size=batch_size, max_len=max_len,\n","                      sample=sample, top_k=top_k, temperature=temperature, burnin=burnin, max_iter=max_iter)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:23:24.361548Z","iopub.status.busy":"2022-07-10T08:23:24.361198Z","iopub.status.idle":"2022-07-10T08:23:24.370250Z","shell.execute_reply":"2022-07-10T08:23:24.369277Z","shell.execute_reply.started":"2022-07-10T08:23:24.361520Z"},"id":"4Tg0ycIaWNBS","outputId":"bf539c32-d804-4449-e33d-7ec9474a2496","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated Rachel's dialogues:\n","[CLS] why don ##t get good form right well said thought said yes knew ross liked conversation ross said say right right said yes said right wrong okay calm calm listen listen listen clearly said listen well listen hear talking conversation [SEP]\n","[CLS] listen can ##t still getting word back rachel tell ross tell rachel tell ask knew rachel know rachel tell ross tell rachel tell ross went play phone phone rachel saw emma know tell rachel got phone rachel gave back phone [SEP]\n","[CLS] guys love you guys think chandler ##s scene mean god honey know chandler ##s phoebe hope phoebe even rachel phoebe feel like phoebe ross want know great phoebe think chandler ##s sex god god could help phoebe make love god [SEP]\n","[CLS] know guys ##t know girls know know play god great much joey ##s emma sandy wan ##s baby joey makes right time maybe joey tries use word anything saying emma make thing something emma feel emma go ##n think something [SEP]\n","[CLS] man joey what ##s getting phone say well really sick care sick sandy know happened thing happened good time good time gavin went show good time show alright ##i leave head give heart yes show see first great time gavin [SEP]\n"]}],"source":["print(\"Generated Rachel's dialogues:\")\n","for sent in rachel_res:\n","    print(' '.join(sent))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-07-10T08:23:28.398933Z","iopub.status.busy":"2022-07-10T08:23:28.398032Z","iopub.status.idle":"2022-07-10T08:23:29.643224Z","shell.execute_reply":"2022-07-10T08:23:29.642021Z","shell.execute_reply.started":"2022-07-10T08:23:28.398870Z"},"id":"1Ad3q5ReT6dH","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in /weights/rachel/config.json\n","Model weights saved in /weights/rachel/pytorch_model.bin\n"]}],"source":["model.save_pretrained(\"/weights/rachel/\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
